<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/logo-1.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="SEEDS Conference">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Schedule | SDA Workshop 2025</title>
    <style>
    HeadColor{
        color:yellow;
    }
    .Programs tr:nth-child(odd) {
            background-color: #e5ecf9;
    }
    </style>
</head>

<body>
    <center>
    <div class="banner">
            <img src="assets/hku_banner.jpg" alt="SDA Workshop Banner" width="100%" height="auto">
        
            <div class="bottom-right" style="font-size:4.3vmin;">
                <HeadColor>June 10, 2025 <br> The University of Hong Kong, Hong Kong </HeadColor>
            </div>
        </div>
    </center>


    <table class="navigation">
        <tr>
            <td class="navigation" style="font-size:4vmin;width: 20%">
                <a title="Conference Home Page" href=".">Home</a>
            </td>
            <td class="navigation" style="font-size:4vmin;width: 25%">
                <a class="current" title="Sessions" href="sessions">Program</a>
            </td>
            <td class="navigation" style="font-size:4vmin;width: 25%">
                <a title="Conference venue" href="venue">Venue & Direction</a>
            </td>
            <td class="navigation" style="font-size:4vmin;width: 30%">
                <a title="Conference Schedule" href="Transportation">Accommodation</a> 
            </td>

        </tr>
    </table>

    <table>
        <tr>
            <td style="font-size:2.3vmin;">
        <span style="color: red;">(New in May 7) All contents are available now!</span><br>
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="title" style="font-size:3.7vmin;">
                Sessions<br>
            </td>
        </tr>
    </table>


    <table>
        <tr>
            <td style="font-size:2.3vmin;">
                Venue: CPD-3.28, Central Podium Levels – Three (Central Podium Levels – Three, <a href="http://www.maps.hku.hk/?type=Locations&id=173&lang=en&name=The%20Jockey%20Club%20Tower">The Jockey Club Tower</a>), Centennial Campus, HKU. <br>
                <!------A PDF version of this page can be found <a href="assets/2025_TBC_Workshop_Program.pdf">here</a>. --->
            </td>
        </tr>
    </table>


    <table id="wholeday" class="Programs" style="width:85%;">
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;width: 15%;">
                08:30 - 09:00
            </td>
            <td class="abstract" style="font-size:2.3vmin;width: 65%;">
                Registration
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                09:00 - 09:10
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Opening: Haipeng Shen & Zhixi Wan
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="sessions" colspan="4" style="font-size:2.3vmin;">
                Session 1, Chair: Haipeng Shen
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                09:10 - 09:50
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                <a href="sessions#Tony_Cai_abstract">Transcending Data Boundaries: Transfer Knowledge in Statistical Learning</a><br>
            </td>
            <td class="abstract" style="font-size:2.3vmin;width: 20%;">
              Tony Cai
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                09:50 - 10:00
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Photo
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                10:00 - 10:30
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Coffee Break
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="sessions" colspan="4" style="font-size:2.3vmin;">
                Session 2, Chair: Dan Yang & Xinghao Qiao
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                10:30 - 11:10
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                <a href="sessions#Rong_Chen_abstract">Dynamic Tensor Factor Model with Main and Interaction Effects</a><br>
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Rong Chen
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                11:10 - 11:50
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                <a href="sessions#Junhui_Wang_abstract">Learning nonparametric graphical model on heterogeneous network-linked data</a><br>
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Junhui Wang
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                11:50 - 14:00
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Lunch Break
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="sessions" colspan="4" style="font-size:2.3vmin;">
                Session 3, Chair: Jing Ouyang & Weichen Wang
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;width: 15%;">
                14:00 - 14:40
            </td>
            <td class="abstract" style="font-size:2.3vmin;width: 65%;">
                <a href="sessions#Yingying_Fan_abstract">Asymptotic FDR Control with Model-X Knockoffs: Is Moments Matching Sufficient?</a><br>
            </td>
            <td class="abstract" style="font-size:2.3vmin;width: 20%;">
                Yingying Fan
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                14:40 - 15:20
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                <a href="sessions#Yongmiao_Hong_abstract">Reinforced Tail Quantile Regression</a><br>
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Yongmiao Hong
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                15:20 - 15:50
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Coffee Break
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="sessions" colspan="4" style="font-size:2.3vmin;">
                Session 4, Chair: Zhanrui Cai & Xin Tong
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                15:50 - 16:30
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                <a href="sessions#Xi_Chen_abstract">Proof-of-Learning: Decentralized Trustworthy AI meets Blockchain</a><br>
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Xi Chen
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                16:30 - 17:00
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                <a href="sessions#Gareth_James_abstract">The Role of Statistics Within Business in the Era of AI</a><br>
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Gareth James
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                17:00 - 17:10
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Coffee Break
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                17:10 - 17:55
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Panel Discussion: Development of Statistics within Business School
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="1" style="font-size:2.3vmin;">
                17:55 - 18:00
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Closing: Xinghao Qiao & Weichen Wang
            </td>
            <td>
            </td>
        </tr>
        <tr>
            <td class="date" rowspan="2" style="font-size:2.3vmin;">
                18:00 - 20:30    
            </td>
            <td class="abstract" style="font-size:2.3vmin;">
                Banquet (invitation only)              
            </td>
            <td>
            </td>
        </tr>
    </table>

    <p>
    </p>
    <br>



    <table>
        <tr>
            <td class="title" style="font-size:4vmin;">
                Abstracts of the talks<br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;text-align:justify">
                (According to alphabetical order)
            </td>
        </tr>
        
    </table>

    <p>
    </p> 

    <table id="Tony_Cai_abstract">
        <tr>
            <td class="title" style="font-size:3vmin;">
                Transcending Data Boundaries: Transfer Knowledge in Statistical Learning <br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
              Tony Cai (University of Pennsylvania)
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;text-align:justify">
                Abstract: Human learners have a natural ability to transfer knowledge from one setting to another, using experience gained in one context to inform learning in a different but related one. This capacity for transfer is fundamental to efficient and adaptive learning. In contrast, most statistical learning procedures are designed to address a single task or learn a single distribution, based solely on data from that specific setting. <br>
                In this talk, I will discuss recent optimality results in statistical transfer learning in various settings, with a primary focus on functional mean estimation and covariance matrix estimation. These results demonstrate the significant benefits of incorporating data from source distributions to enhance learning performance under the target distribution.
            </td>
        </tr>
    </table>

    <table id="Rong_Chen_abstract">
        <tr>
            <td class="title" style="font-size:3vmin;">
                Dynamic Tensor Factor Model with Main and Interaction Effects <br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
              Rong Chen (Rutgers University)
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;text-align:justify">
                Abstract: High dimensional tensor time series has been encountered increasingly often in applications. Factor model in a form similar to tensor Tucker decomposition has been shown to be a useful model for tensor time series. In this paper we propose a more detailed decomposition so the factors can be interpreted as global effects, main effects of individual modes (columns, rows, etc), and interaction effects among the modes. This decomposition enhances interpretability, effective dimension reduction and estimation efficiency. Theoretical investigation establishes the properties of the estimation procedure. Empirical examples are used to illustrate the applicability of the methodology, highlighting its relevance to contemporary data science challenges in high-dimensional settings.
            </td>
        </tr>
    </table>

    <table id="Xi_Chen_abstract">
        <tr>
            <td class="title" style="font-size:3vmin;">
                Proof-of-Learning: Decentralized Trustworthy AI meets Blockchain <br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
              Xi Chen (New York University)
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;text-align:justify">
                Abstract: Blockchain technology and artificial intelligence are two transformative technologies that face key challenges: blockchain systems struggle with energy efficiency and sustainability, while AI systems grapple with trust and transparency. This talk presents recent advances in Proof-of-Learning (PoL), a novel consensus mechanism that elegantly addresses both challenges by incorporating machine learning training as useful work for blockchain mining. We introduce an incentive-secure PoL mechanism that achieves computational efficiency, controllable difficulty, and provable security guarantees, improving upon previous approaches with significantly lower computational overhead. We also present a novel peer-prediction solution that resolves the critical "Verifier's Dilemma". Together, these advances establish a theoretical foundation for building sustainable blockchain systems while simultaneously creating a decentralized, trustworthy platform for AI verification.
            </td>
        </tr>
    </table>


    <table id="Yingying_Fan_abstract">
        <tr>
            <td class="title" style="font-size:3vmin;">
                Asymptotic FDR Control with Model-X Knockoffs: Is Moments Matching Sufficient? <br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
              Yingying Fan (University of Southern California)
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;text-align:justify">
                Abstract: We propose a unified theoretical framework for studying the robustness of the model-X knockoffs framework by investigating the asymptotic false discovery rate (FDR) control of the practically implemented approximate knockoffs procedure. This procedure deviates from the model-X knockoffs framework by substituting the true covariate distribution with a user-specified distribution that can be learned using in-sample observations. By replacing the distributional exchangeability condition of the model-X knockoff variables with three conditions on the approximate knockoff statistics, we establish that the approximate knockoffs procedure achieves the asymptotic FDR control. Using our unified framework, we further prove that an arguably most popularly used knockoff variable generation method--the Gaussian knockoffs generator based on the first two moments matching--achieves the asymptotic FDR control when the two-moment-based knockoff statistics are employed in the knockoffs inference procedure. For the first time in the literature, our theoretical results justify formally the effectiveness and robustness of the Gaussian knockoffs generator. Simulation and real data examples are conducted to validate the theoretical findings.
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
              <a href="https://arxiv.org/abs/2502.05969">Arxiv Link</a>
            </td>
        </tr>
    </table>

    <table id="Yongmiao_Hong_abstract">
        <tr>
            <td class="title" style="font-size:3vmin;">
                Reinforced Tail Quantile Regression <br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
              Yongmiao Hong (University of Chinese Academy of Sciences)
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;text-align:justify">
                Abstract: Quantile regression in the tails suffers from inconsistency and a non-normal asymptotic distribution due to data sparsity. To address this situation, we propose a reinforced tail quantile regression estimator that leverages the power-law behavior for heavy-tailed data. Our estimator is both consistent and asymptotically normal under some regularity conditions. Furthermore, we establish the asymptotic validity of bootstrap inference using random weights. Simulation results demonstrate the superior performance of our estimator and the near-exact coverage of the bootstrap confidence intervals. In particular, our method yields narrower confidence intervals compared to existing approaches. We apply the proposed method to examine the marginal effect of education on the upper extreme percentiles of income, using a unique dataset from the Chinese Twins Survey conducted by the National Bureau of Statistics. The sample includes 2,412 individuals, with an average monthly income of CNY 912 in 2002. The income distribution exhibits heavy-tailed behavior, with a tail index estimated at 2, implying that the moments of order higher than two may not exist. Our method uncovers a significantly positive effect of education in the tail, in contrast to existing approaches, which yield insignificant or even negative effects, often accompanied by wide confidence intervals. Notably, the width of the confidence intervals from our method remains stable in the tail region and is comparable to that of the standard quantile regression at fixed quantile levels.
            </td>
        </tr>
    </table>

    <table id="Gareth_James_abstract">
        <tr>
            <td class="title" style="font-size:3vmin;">
                The Role of Statistics Within Business in the Era of AI <br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
              Gareth James (Emory University)
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;text-align:justify">
                Abstract: The 2010’s saw a dramatic increase in the availability of business data and a corresponding rise in the importance of data science and machine learning. As a result, we have seen significant growth in the numbers of statisticians and computer scientists within business schools. Arguably, the first half of the 2020’s has seen an even more dramatic revolution, with AI taking center stage. While we are all trying to assess the long-term impacts of AI, it is clear that these Large Language Model (LLM) technologies pose both opportunities and challenges for statisticians. In this seminar I will present some of my perspectives on this topic as a statistician with over 25 years’ experience teaching in, and leading, business schools.
            </td>
        </tr>
    </table>


    <table id="Junhui_Wang_abstract">
        <tr>
            <td class="title" style="font-size:3vmin;">
                Learning nonparametric graphical model on heterogeneous network-linked data <br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
              Junhui Wang (The Chinese University of Hong Kong)
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;text-align:justify">
                Graphical models have been popularly used for capturing conditional independence structure in multivariate data, which are often built upon independent and identically distributed observations, limiting their applicability to complex datasets such as network-linked data. In this talk, we introduce a nonparametric graphical model that addresses these limitations by accommodating heterogeneous graph structures without imposing any specific distributional assumptions. The introduced estimation method effectively integrates network embedding with nonparametric graphical model estimation. It further transforms the graph learning task into solving a finitedimensional linear equation system by leveraging the properties of vectorvalued reproducing kernel Hilbert space. We will also discuss theoretical properties of the proposed method in terms of the estimation consistency and exact recovery of the heterogeneous graph structures. Its effectiveness is also demonstrated through a variety of simulated examples and a real application to the statistician coauthorship dataset.
            </td>
        </tr>
    </table>

    <!--  Abstract Template

    <table id="Name_abstract">
        <tr>
            <td class="title">
                Title<br>
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a href="">Name</a> (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Abstract
            </td>
        </tr>
    </table>

    -->




    <!--  Abstract Template

    <table id="Name_abstract">
        <tr>
            <td class="title" style="font-size:3vmin;">
                Title<br>
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
                Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract" style="font-size:2.3vmin;">
                Abstract
            </td>
        </tr>
    </table>

    -->




    <footer>
        &copy; Stat Group @ HKU Business School.
    </footer>

</body>
</html>
